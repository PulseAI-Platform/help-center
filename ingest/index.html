<!DOCTYPE html><html  data-capo=""><head><meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Ingest Tool</title>
<style>.global-container{background-color:#3f3838!important;color:#fff;display:flex;flex-direction:column;min-height:100vh}</style>
<style>.page-container[data-v-d0170b03]{background-color:#3f3838;font-family:Inter,sans-serif;line-height:1.6;margin:0 auto;max-width:800px;padding:20px}.page-container[data-v-d0170b03],h1[data-v-d0170b03],h2[data-v-d0170b03],h3[data-v-d0170b03],h4[data-v-d0170b03]{color:#fff!important}ul[data-v-d0170b03]{list-style-type:disc;padding-left:20px}code[data-v-d0170b03]{background-color:#555;border-radius:5px;color:#fff!important;font-family:Courier New,monospace;padding:4px 6px}a[data-v-d0170b03],a[data-v-d0170b03]:active,a[data-v-d0170b03]:hover,a[data-v-d0170b03]:visited{color:#fff!important;text-decoration:none!important}a[data-v-d0170b03]:hover{text-decoration:underline!important}</style>
<link rel="stylesheet" href="/_nuxt/entry.CuGsKrEI.css" crossorigin>
<link rel="preload" as="fetch" crossorigin="anonymous" href="/ingest/_payload.json?48c30e33-0694-43a9-862b-2e4ed148e64d">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/7Mg-_QcM.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/BsqVP5bk.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/DcV9Ebhu.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/B5WT8XVG.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/BWOU0wYs.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/CxYJgpPD.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/DOwJDukw.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/DfkUx7uO.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/titg7IKR.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/CfKEctlU.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/CGjryXvn.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/CMxbkb0_.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/CekaGkSt.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/Dwh758lU.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/CQOwukbv.js">
<link rel="prefetch" as="style" crossorigin href="/_nuxt/useStudio.Tc7-ghOt.css">
<link rel="prefetch" as="script" crossorigin href="/_nuxt/BtwDATX-.js">
<link rel="prefetch" as="script" crossorigin href="/_nuxt/SHPqkKXL.js">
<link rel="prefetch" as="script" crossorigin href="/_nuxt/DL_O0Q6O.js">
<link rel="prefetch" as="script" crossorigin href="/_nuxt/Dh1giiT9.js">
<link rel="prefetch" as="script" crossorigin href="/_nuxt/Q4MuPlop.js">
<meta property="og:title" content="Ingest Tool">
<meta name="description" content="The ingest tool converts data from videos, documents, audio files, spreadsheets, and images (with more to come) into tagged, structured, digests according to your prompt. Here's an overview of how ingest currently handles each type of document:">
<meta property="og:description" content="The ingest tool converts data from videos, documents, audio files, spreadsheets, and images (with more to come) into tagged, structured, digests according to your prompt. Here's an overview of how ingest currently handles each type of document:">
<script type="module" src="/_nuxt/7Mg-_QcM.js" crossorigin></script>
<link rel="preload" as="fetch" fetchpriority="low" crossorigin="anonymous" href="/_nuxt/builds/meta/48c30e33-0694-43a9-862b-2e4ed148e64d.json"></head><body><div id="__nuxt"><div class="global-container"><!--[--><main class="page-container" data-v-d0170b03><!--[--><div><h1 id="ingest-tool"><!--[-->Ingest Tool<!--]--></h1><p><!--[-->The ingest tool converts data from videos, documents, audio files, spreadsheets, and images (with more to come) into tagged, structured, digests according to your prompt. Here&#39;s an overview of how ingest currently handles each type of document:<!--]--></p><h1 id="videos"><!--[--><strong><!--[-->Videos<!--]--></strong><!--]--></h1><ul><!--[--><li><!--[-->Videos can be ingested whole but keep in mind the ingesting agent will only be given 20 frames of video from each clip for context along with the matching audio<!--]--></li><li><!--[-->Set the clip length to divide the video in to segments of that length, the agent will receive 20 equally spaced frames for evaluation<!--]--></li><li><!--[-->clip length can be thought of as the &quot;resolution&quot; you want to look at the video under<!--]--></li><li><!--[-->example 1: to get analysis of an intense soccer clip it would be best to keep clip length to around 20 seconds to make sure the AI captures all the information<!--]--></li><li><!--[-->example 2: if you&#39;re just looking at a podcast you may mostly want analysis of the audio context and submit the entire video as a single clip<!--]--></li><li><!--[-->The context prompt can be used to request structured output (ex: &quot;count the number of people in the photos and output only peoplecount: N (newline) scenedescription: description&quot;)<!--]--></li><!--]--></ul><h1 id="audio"><!--[-->Audio<!--]--></h1><ul><!--[--><li><!--[-->Audio files can be ingested and transcribed whole or using clip length, similar to video<!--]--></li><li><!--[-->Audio transcription currently does not support context prompts, as soon as a model becomes available that will this feature will be added to the next sprint<!--]--></li><!--]--></ul><h1 id="images"><!--[-->Images<!--]--></h1><ul><!--[--><li><!--[-->Images can be transcribed with or without a context prompt<!--]--></li><li><!--[-->If ingested without a context prompt the default prompt will instruct the ingesting agent to describe the image in a paragraph of text<!--]--></li><li><!--[-->Context prompts can be used to gather specific information and structure output, this is very useful for quality control and customer service scenarios<!--]--></li><li><!--[-->Example: &quot;Please create structured entries with failure_mode: failure mode (newline) product_name: (newline) scene_description: scene description&quot;<!--]--></li><!--]--></ul><h1 id="documents"><!--[-->Documents<!--]--></h1><p><!--[--><strong><!--[-->Simple documents<!--]--></strong><!--]--></p><ul><!--[--><li><!--[-->RTF and TXT files are read directly into whole entries or into entries the length of the Chunk Size setting<!--]--></li><li><!--[-->Word and ODF documents are currently ingested as text-only (graphs will not currently be &quot;read&quot; by the ingest tool)<!--]--></li><!--]--></ul><p><!--[--><strong><!--[-->PDFs<!--]--></strong><!--]--></p><ul><!--[--><li><!--[-->Image Pdfs: Image PDFs are &quot;transcribed-described&quot; (an image recognition model is used to both transcribe the document and describe any figures) page by page, each page currently becomes a new feed entry<!--]--></li><li><!--[-->Text Pdfs: Text PDFs are read and chunked like simple documents<!--]--></li><li><!--[-->&quot;Image PDF Mode&quot; is triggered when a PDF does not have a proportionately high amount of text defined in its data structure<!--]--></li><!--]--></ul><h1 id="spreadsheets"><!--[-->Spreadsheets<!--]--></h1><ul><!--[--><li><!--[-->Spreadsheets are ingested such that each row becomes its own feed entry (while this may initially seem like it creates performance concerns our backend effectively runs off of a RAM Disk)<!--]--></li><li><!--[-->Multiple worksheet ingestion is supported<!--]--></li><li><!--[-->Ingestion of graphs/etc is not currently supported, but can be emulated by uploading screenshots of graphs if needed<!--]--></li><!--]--></ul><h1 id="tag-selection"><!--[-->Tag Selection<!--]--></h1><ul><!--[--><li><!--[-->Tags can be selected to apply to the new feed entries for all ingestion workflows<!--]--></li><!--]--></ul></div><!--]--></main><!--]--></div></div><div id="teleports"></div><script type="application/json" data-nuxt-data="nuxt-app" data-ssr="true" id="__NUXT_DATA__" data-src="/ingest/_payload.json?48c30e33-0694-43a9-862b-2e4ed148e64d">[{"state":1,"once":260,"_errors":261,"serverRendered":264,"path":7,"prerenderedAt":265},["Reactive",2],{"$sdd-pages":3,"$sdd-surrounds":222,"$sdd-globals":240,"$sdd-navigation":242},["ShallowRef",4],["ShallowReactive",5],{"/ingest":6},{"_path":7,"_dir":8,"_draft":9,"_partial":9,"_locale":8,"title":10,"description":11,"body":12,"_type":215,"_id":216,"_source":217,"_file":218,"_stem":219,"_extension":220,"layout":221},"/ingest","",false,"Ingest Tool","The ingest tool converts data from videos, documents, audio files, spreadsheets, and images (with more to come) into tagged, structured, digests according to your prompt. Here's an overview of how ingest currently handles each type of document:",{"type":13,"children":14,"toc":212},"root",[15,23,28,38,73,79,92,98,121,127,135,148,156,174,180,198,204],{"type":16,"tag":17,"props":18,"children":20},"element","h1",{"id":19},"ingest-tool",[21],{"type":22,"value":10},"text",{"type":16,"tag":24,"props":25,"children":26},"p",{},[27],{"type":22,"value":11},{"type":16,"tag":17,"props":29,"children":31},{"id":30},"videos",[32],{"type":16,"tag":33,"props":34,"children":35},"strong",{},[36],{"type":22,"value":37},"Videos",{"type":16,"tag":39,"props":40,"children":41},"ul",{},[42,48,53,58,63,68],{"type":16,"tag":43,"props":44,"children":45},"li",{},[46],{"type":22,"value":47},"Videos can be ingested whole but keep in mind the ingesting agent will only be given 20 frames of video from each clip for context along with the matching audio",{"type":16,"tag":43,"props":49,"children":50},{},[51],{"type":22,"value":52},"Set the clip length to divide the video in to segments of that length, the agent will receive 20 equally spaced frames for evaluation",{"type":16,"tag":43,"props":54,"children":55},{},[56],{"type":22,"value":57},"clip length can be thought of as the \"resolution\" you want to look at the video under",{"type":16,"tag":43,"props":59,"children":60},{},[61],{"type":22,"value":62},"example 1: to get analysis of an intense soccer clip it would be best to keep clip length to around 20 seconds to make sure the AI captures all the information",{"type":16,"tag":43,"props":64,"children":65},{},[66],{"type":22,"value":67},"example 2: if you're just looking at a podcast you may mostly want analysis of the audio context and submit the entire video as a single clip",{"type":16,"tag":43,"props":69,"children":70},{},[71],{"type":22,"value":72},"The context prompt can be used to request structured output (ex: \"count the number of people in the photos and output only peoplecount: N (newline) scenedescription: description\")",{"type":16,"tag":17,"props":74,"children":76},{"id":75},"audio",[77],{"type":22,"value":78},"Audio",{"type":16,"tag":39,"props":80,"children":81},{},[82,87],{"type":16,"tag":43,"props":83,"children":84},{},[85],{"type":22,"value":86},"Audio files can be ingested and transcribed whole or using clip length, similar to video",{"type":16,"tag":43,"props":88,"children":89},{},[90],{"type":22,"value":91},"Audio transcription currently does not support context prompts, as soon as a model becomes available that will this feature will be added to the next sprint",{"type":16,"tag":17,"props":93,"children":95},{"id":94},"images",[96],{"type":22,"value":97},"Images",{"type":16,"tag":39,"props":99,"children":100},{},[101,106,111,116],{"type":16,"tag":43,"props":102,"children":103},{},[104],{"type":22,"value":105},"Images can be transcribed with or without a context prompt",{"type":16,"tag":43,"props":107,"children":108},{},[109],{"type":22,"value":110},"If ingested without a context prompt the default prompt will instruct the ingesting agent to describe the image in a paragraph of text",{"type":16,"tag":43,"props":112,"children":113},{},[114],{"type":22,"value":115},"Context prompts can be used to gather specific information and structure output, this is very useful for quality control and customer service scenarios",{"type":16,"tag":43,"props":117,"children":118},{},[119],{"type":22,"value":120},"Example: \"Please create structured entries with failure_mode: failure mode (newline) product_name: (newline) scene_description: scene description\"",{"type":16,"tag":17,"props":122,"children":124},{"id":123},"documents",[125],{"type":22,"value":126},"Documents",{"type":16,"tag":24,"props":128,"children":129},{},[130],{"type":16,"tag":33,"props":131,"children":132},{},[133],{"type":22,"value":134},"Simple documents",{"type":16,"tag":39,"props":136,"children":137},{},[138,143],{"type":16,"tag":43,"props":139,"children":140},{},[141],{"type":22,"value":142},"RTF and TXT files are read directly into whole entries or into entries the length of the Chunk Size setting",{"type":16,"tag":43,"props":144,"children":145},{},[146],{"type":22,"value":147},"Word and ODF documents are currently ingested as text-only (graphs will not currently be \"read\" by the ingest tool)",{"type":16,"tag":24,"props":149,"children":150},{},[151],{"type":16,"tag":33,"props":152,"children":153},{},[154],{"type":22,"value":155},"PDFs",{"type":16,"tag":39,"props":157,"children":158},{},[159,164,169],{"type":16,"tag":43,"props":160,"children":161},{},[162],{"type":22,"value":163},"Image Pdfs: Image PDFs are \"transcribed-described\" (an image recognition model is used to both transcribe the document and describe any figures) page by page, each page currently becomes a new feed entry",{"type":16,"tag":43,"props":165,"children":166},{},[167],{"type":22,"value":168},"Text Pdfs: Text PDFs are read and chunked like simple documents",{"type":16,"tag":43,"props":170,"children":171},{},[172],{"type":22,"value":173},"\"Image PDF Mode\" is triggered when a PDF does not have a proportionately high amount of text defined in its data structure",{"type":16,"tag":17,"props":175,"children":177},{"id":176},"spreadsheets",[178],{"type":22,"value":179},"Spreadsheets",{"type":16,"tag":39,"props":181,"children":182},{},[183,188,193],{"type":16,"tag":43,"props":184,"children":185},{},[186],{"type":22,"value":187},"Spreadsheets are ingested such that each row becomes its own feed entry (while this may initially seem like it creates performance concerns our backend effectively runs off of a RAM Disk)",{"type":16,"tag":43,"props":189,"children":190},{},[191],{"type":22,"value":192},"Multiple worksheet ingestion is supported",{"type":16,"tag":43,"props":194,"children":195},{},[196],{"type":22,"value":197},"Ingestion of graphs/etc is not currently supported, but can be emulated by uploading screenshots of graphs if needed",{"type":16,"tag":17,"props":199,"children":201},{"id":200},"tag-selection",[202],{"type":22,"value":203},"Tag Selection",{"type":16,"tag":39,"props":205,"children":206},{},[207],{"type":16,"tag":43,"props":208,"children":209},{},[210],{"type":22,"value":211},"Tags can be selected to apply to the new feed entries for all ingestion workflows",{"title":8,"searchDepth":213,"depth":213,"links":214},2,[],"markdown","content:ingest.md","content","ingest.md","ingest","md","default",["ShallowRef",223],["ShallowReactive",224],{"/ingest":225},[226,233],{"_path":227,"_dir":8,"_draft":9,"_partial":9,"_locale":8,"title":228,"description":229,"_type":215,"_id":230,"_source":217,"_file":231,"_stem":232,"_extension":220},"/","Welcome to Pulse!","Here's a table of contents:","content:index.md","index.md","index",{"_path":234,"_dir":8,"_draft":9,"_partial":9,"_locale":8,"title":235,"description":236,"_type":215,"_id":237,"_source":217,"_file":238,"_stem":239,"_extension":220},"/intro","Introduction","Pulse is a decentralized, model-agnostic, AI-powered platform designed to compress web functionality into a single peer-to-peer application. It enables users to:","content:intro.md","intro.md","intro",["ShallowRef",241],{},[243,246,249,250,251,252,255,258],{"title":244,"_path":245},"About Content v2","/about",{"title":247,"_path":248},"Digests","/digests",{"title":228,"_path":227},{"title":10,"_path":7},{"title":235,"_path":234},{"title":253,"_path":254},"Pulse for IOT","/pulse_iot",{"title":256,"_path":257},"Search tool (Working title: Quantum Search)","/search",{"title":235,"_path":259},"/vector_search",["Set"],["ShallowReactive",262],{"$udKvjfRFXT":263,"content-query-E2bB6SR2bW":263},null,true,1739039766249]</script>
<script>window.__NUXT__={};window.__NUXT__.config={public:{studioApi:"",mdc:{components:{prose:true,map:{p:"prose-p",a:"prose-a",blockquote:"prose-blockquote","code-inline":"prose-code-inline",code:"ProseCodeInline",em:"prose-em",h1:"prose-h1",h2:"prose-h2",h3:"prose-h3",h4:"prose-h4",h5:"prose-h5",h6:"prose-h6",hr:"prose-hr",img:"prose-img",ul:"prose-ul",ol:"prose-ol",li:"prose-li",strong:"prose-strong",table:"prose-table",thead:"prose-thead",tbody:"prose-tbody",td:"prose-td",th:"prose-th",tr:"prose-tr"}},headings:{anchorLinks:{h1:false,h2:true,h3:true,h4:true,h5:false,h6:false}}},content:{locales:[],defaultLocale:"",integrity:1739039751814,experimental:{stripQueryParameters:false,advanceQuery:false,clientDB:false},respectPathCase:false,api:{baseURL:"/api/_content"},navigation:{fields:["layout"]},tags:{p:"prose-p",a:"prose-a",blockquote:"prose-blockquote","code-inline":"prose-code-inline",code:"ProseCodeInline",em:"prose-em",h1:"prose-h1",h2:"prose-h2",h3:"prose-h3",h4:"prose-h4",h5:"prose-h5",h6:"prose-h6",hr:"prose-hr",img:"prose-img",ul:"prose-ul",ol:"prose-ol",li:"prose-li",strong:"prose-strong",table:"prose-table",thead:"prose-thead",tbody:"prose-tbody",td:"prose-td",th:"prose-th",tr:"prose-tr"},highlight:false,wsUrl:"",documentDriven:{page:true,navigation:true,surround:true,globals:{},layoutFallbacks:["theme"],injectPage:true},host:"",trailingSlash:false,search:"",contentHead:true,anchorLinks:{depth:4,exclude:[1]}},studio:{apiURL:"https://api.nuxt.studio",iframeMessagingAllowedOrigins:""}},app:{baseURL:"/",buildId:"48c30e33-0694-43a9-862b-2e4ed148e64d",buildAssetsDir:"/_nuxt/",cdnURL:""}}</script></body></html>